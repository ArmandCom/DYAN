{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "## Imports related to PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.misc\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from pylab import imshow, show, get_cmap\n",
    "\n",
    "## Generic imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Dependencies classes and functions\n",
    "from utils import gridRing\n",
    "from utils import asMinutes\n",
    "from utils import timeSince\n",
    "from utils import getWeights\n",
    "from utils import videoDataset\n",
    "from utils import save_checkpoint\n",
    "from utils import getListOfFolders\n",
    "\n",
    "## Import Model\n",
    "from DyanOF import OFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(arr, window_size):\n",
    "    \"\"\" Construct a sliding window view of the array\"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    window_size = int(window_size)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(\"need 2-D input\")\n",
    "    if not (window_size > 0):\n",
    "        raise ValueError(\"need a positive window size\")\n",
    "    shape = (arr.shape[0] - window_size + 1,\n",
    "             arr.shape[1] - window_size + 1,\n",
    "             window_size, window_size)\n",
    "    if shape[0] <= 0:\n",
    "        shape = (1, shape[1], arr.shape[0], shape[3])\n",
    "    if shape[1] <= 0:\n",
    "        shape = (shape[0], 1, shape[2], arr.shape[1])\n",
    "    strides = (arr.shape[1]*arr.itemsize, arr.itemsize,\n",
    "               arr.shape[1]*arr.itemsize, arr.itemsize)\n",
    "    return as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "def cell_neighbors(arr, i, j, d):\n",
    "    \"\"\"Return d-th neighbors of cell (i, j)\"\"\"\n",
    "    w = sliding_window(arr, 2*d+1)\n",
    "    ix = np.clip(i - d, 0, w.shape[0]-1)\n",
    "    jx = np.clip(j - d, 0, w.shape[1]-1)\n",
    "    \n",
    "    i0 = max(0, i - d - ix)\n",
    "    j0 = max(0, j - d - jx)\n",
    "    i1 = w.shape[2] - max(0, d - i + ix)\n",
    "    j1 = w.shape[3] - max(0, d - j + jx)\n",
    "\n",
    "    return w[ix, jx][i0:i1,j0:j1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HyperParameters for the Network\n",
    "NumOfPoles = 40\n",
    "EPOCH = 300\n",
    "BATCH_SIZE = 1\n",
    "LR = 0.0015\n",
    "gpu_id = 1  # 3?\n",
    "\n",
    "## For training UCF\n",
    "# Input -  3 Optical Flow\n",
    "# Output - 1 Optical Flow\n",
    "## For training Kitti\n",
    "# Input -  9 Optical Flow\n",
    "# Output - 1 Optical Flow\n",
    "\n",
    "FRA = 3 # input number of frame\n",
    "PRE = 1 # output number of frame\n",
    "N_FRAME = FRA+PRE\n",
    "N = NumOfPoles*4\n",
    "T = FRA # number of row in dictionary(same as input number of frame)\n",
    "saveEvery = 2\n",
    "N_FRAME_FOLDER = 18\n",
    "\n",
    "#mnist\n",
    "x_fra = 64\n",
    "y_fra = 64\n",
    "\n",
    "## Load saved model\n",
    "load_ckpt = False\n",
    "ckpt_file = 'MS_Model_4px_22.pth' # for Kitti Dataset: 'KittiModel.pth'\n",
    "# checkptname = \"UCFModel\"\n",
    "checkptname = \"MS_Model_4px_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load input data\n",
    "\n",
    "# set train list name:\n",
    "trainFolderFile = './datasets/DisentanglingMotion/importing_data/moving_symbols/MovingSymbols2_trainlist.txt'\n",
    "# trainFolderFile = 'trainlist01.txt'\n",
    "\n",
    "# set training data directory:\n",
    "rootDir = './datasets/DisentanglingMotion/importing_data/moving_symbols/output/MovingSymbols2_same_4px-OF/train'\n",
    "# rootDir = './datasets/UCF-101-Frames'\n",
    "\n",
    "trainFoldeList = getListOfFolders(trainFolderFile)[::10]\n",
    "# if Kitti dataset: use listOfFolders instead of trainFoldeList\n",
    "# listOfFolders = [name for name in os.listdir(rootDir) if os.path.isdir(os.path.join(rootDir, name))]\n",
    "\n",
    "\n",
    "trainingData = videoDataset(folderList=trainFoldeList,\n",
    "                            rootDir=rootDir,\n",
    "                            N_FRAME=N_FRAME,\n",
    "                            N_FRAME_FOLDER = N_FRAME_FOLDER)\n",
    "\n",
    "dataloader = DataLoader(trainingData,\n",
    "                        batch_size=BATCH_SIZE ,\n",
    "                        shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing r, theta\n",
    "P,Pall = gridRing(N)\n",
    "Drr = abs(P)\n",
    "Drr = torch.from_numpy(Drr).float()\n",
    "Dtheta = np.angle(P)\n",
    "Dtheta = torch.from_numpy(Dtheta).float()\n",
    "# What and where is gamma\n",
    "\n",
    "## Create the model\n",
    "model = OFModel(Drr, Dtheta, T, PRE, gpu_id)\n",
    "model.cuda(gpu_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[50,100], gamma=0.1) # if Kitti: milestones=[100,150]\n",
    "loss_mse = nn.MSELoss()\n",
    "start_epoch = 1\n",
    "\n",
    "## If want to continue training from a checkpoint\n",
    "if(load_ckpt):\n",
    "    loadedcheckpoint = torch.load(ckpt_file)\n",
    "    start_epoch = loadedcheckpoint['epoch']\n",
    "    model.load_state_dict(loadedcheckpoint['state_dict'])\n",
    "    optimizer.load_state_dict(loadedcheckpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training from epoch: \", start_epoch)\n",
    "print('-' * 25)\n",
    "start = time.time()\n",
    "\n",
    "count = 0\n",
    "## Start the Training\n",
    "for epoch in range(start_epoch, EPOCH+1):\n",
    "    loss_value = []\n",
    "    scheduler.step()\n",
    "    for i_batch, sample in enumerate(dataloader):\n",
    "        for n in range(N_FRAME_FOLDER-N_FRAME):\n",
    "            \n",
    "            data = sample['frames'].squeeze(0).cuda(gpu_id)\n",
    "            expectedOut = Variable(data)\n",
    "            \n",
    "            inputData = Variable(data[:,n:(n+FRA),:])\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(inputData)\n",
    "            loss = loss_mse(output[:,FRA], expectedOut[:,n+FRA])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_value.append(loss.data.item())\n",
    "\n",
    "            # Visualize expected and output images.\n",
    "            po = output.data.cpu().numpy()\n",
    "            eo = expectedOut.data.cpu().numpy()\n",
    "            tmp1 = np.zeros([64, 64, 3], dtype=np.float16)\n",
    "            tmp1[:, :, 0] = po[0, FRA, :].reshape(x_fra, y_fra)\n",
    "            tmp1[:, :, 1] = po[1, FRA, :].reshape(x_fra, y_fra)\n",
    "\n",
    "            scipy.misc.imsave('predicted_outputOF.png', tmp1)\n",
    "\n",
    "            tmp2 = np.zeros([64, 64, 3], dtype=np.float16)\n",
    "            tmp2[:, :, 0] = eo[0, n+FRA, :].reshape(x_fra, y_fra)\n",
    "            tmp2[:, :, 1] = eo[1, n+FRA, :].reshape(x_fra, y_fra)\n",
    "\n",
    "            scipy.misc.imsave('expected_outputOF.png', tmp2)\n",
    "\n",
    "    loss_val = np.mean(np.array(loss_value))\n",
    "\n",
    "    if epoch % saveEvery ==0 :\n",
    "        save_checkpoint({\t'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer' : optimizer.state_dict(),\n",
    "                            },checkptname+str(epoch)+'.pth')\n",
    "\n",
    "    if epoch % 4 == 0:\n",
    "        print(model.state_dict()['l1.rr'])\n",
    "        print(model.state_dict()['l1.theta'])\n",
    "        # loss_val = float(loss_val/i_batch)\n",
    "    print('Epoch: ', epoch, '| train loss: %.4f' % loss_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
