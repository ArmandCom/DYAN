{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'alignOFtest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-add7b0218548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m## Dependencies classes and functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malignOFtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDyanOF\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOFModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDyanOF\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreatRealDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'alignOFtest'"
     ]
    }
   ],
   "source": [
    "## Imports related to PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "## Generic imports\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import hankel\n",
    "from skimage import io, transform\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "## Dependencies classes and functions\n",
    "from utils import *\n",
    "from utils import alignOFtest\n",
    "from DyanOF import OFModel\n",
    "from DyanOF import creatRealDictionary\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "from scipy.misc import imread, imresize\n",
    "from skimage.measure import compare_mse as mse\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "#from sklearn import preprocessing\n",
    "############################# Import Section #################################\n",
    "import math\n",
    "from pylab import imshow, show, get_cmap\n",
    "#import imutils\n",
    "import cv2\n",
    "import scipy\n",
    "import math\n",
    "start = time.time()\n",
    "from pyflow import pyflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "FRA = 9\n",
    "PRE = 1\n",
    "N_FRAME = FRA+PRE\n",
    "T = FRA\n",
    "lam = 0.5\n",
    "\n",
    "def loadModel(ckpt_file):\n",
    "    loadedcheckpoint = torch.load(ckpt_file)\n",
    "    #model.load_state_dict(loadedcheckpoint['state_dict'])\n",
    "    #optimizer.load_state_dict(loadedcheckpoint['optimizer'])\n",
    "    stateDict = loadedcheckpoint['state_dict']\n",
    "\n",
    "    # load parameters\n",
    "    Dtheta = stateDict['l1.theta']\n",
    "    Drr    = stateDict['l1.rr']\n",
    "    model = OFModel(Drr, Dtheta, T, PRE, lam, gpu_id)\n",
    "    model.cuda(gpu_id)\n",
    "    Drr = Variable(Drr.cuda(gpu_id))\n",
    "    Dtheta = Variable(Dtheta.cuda(gpu_id))\n",
    "    dictionary = creatRealDictionary(N_FRAME,Drr,Dtheta, gpu_id)\n",
    "\n",
    "    return model, dictionary, Drr, Dtheta\n",
    "\n",
    "def process_im(im, desired_sz=(128, 160)):\n",
    "    target_ds = float(desired_sz[0])/im.shape[0]\n",
    "    im = imresize(im, (desired_sz[0], int(np.round(target_ds * im.shape[1]))))\n",
    "    d = int((im.shape[1] - desired_sz[1]) / 2)\n",
    "    im = im[:, d:d+desired_sz[1]]\n",
    "    # im = imutils.resize(im, width=160,height=128)\n",
    "    return im\n",
    "\n",
    "\n",
    "def SSIM(predi,pix):\n",
    "    pix = pix.astype(float)\n",
    "    predict = predi.astype(float)\n",
    "    ssim_score = measure.compare_ssim(pix, predict, win_size=11, data_range = 1.,multichannel=True,\n",
    "                    gaussian_weights=True,sigma = 1.5,use_sample_covariance=False,\n",
    "                    K1=0.01,K2=0.03)\n",
    "\n",
    "    return ssim_score\n",
    "\n",
    "\n",
    "def scipwarp(img, u, v):\n",
    "    M, N, _ = img.shape\n",
    "    x = np.linspace(0,N-1, N)\n",
    "    y = np.linspace(0,M-1, M)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    x += u\n",
    "    y += v\n",
    "    warped = img\n",
    "    warped[:,:,0] = scipy.ndimage.map_coordinates(img[:,:,0], [y.ravel(),x.ravel()], order=1, mode='nearest').reshape(img.shape[0],img.shape[1])\n",
    "    warped[:,:,1] = scipy.ndimage.map_coordinates(img[:,:,1], [y.ravel(),x.ravel()], order=1, mode='nearest').reshape(img.shape[0],img.shape[1])\n",
    "    warped[:,:,2] = scipy.ndimage.map_coordinates(img[:,:,2], [y.ravel(),x.ravel()], order=1, mode='nearest').reshape(img.shape[0],img.shape[1])\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.012\n",
    "ratio = 0.75\n",
    "minWidth = 20\n",
    "nOuterFPIterations = 7\n",
    "nInnerFPIterations = 1\n",
    "nSORIterations = 30\n",
    "colType = 0\n",
    "\n",
    "import time\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "\n",
    "gpu_id = 0\n",
    "ckpt_file = '/home/armandcomas/DYAN/preTrainedModel/' \\\n",
    "              'Kitti_ChaseOF_not-std_lam01_lossFuPRE_FRA9-PRE1_Comp-ori_70.pth'\n",
    "rootDir = '/home/armandcomas/datasets/Caltech/images'\n",
    "\n",
    "## Load model from a checkpoint file\n",
    "\n",
    "folderList = ['set10V011'] # set10V011\n",
    "__imgsize__ = (128,160)\n",
    "mse = []\n",
    "ssim = []\n",
    "psnr = []\n",
    "c_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set10V011\n",
      "1733\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'alignOFtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f84ad36991d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#sample[0,0,10290] = 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0malSample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malignOFtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mshowOFs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malSample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#alSample = sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alignOFtest' is not defined"
     ]
    }
   ],
   "source": [
    "for folder in folderList:\n",
    "    print(folder)\n",
    "    frames = [each for each in os.listdir(os.path.join(rootDir, folder)) if each.endswith(('.jpg','.jpeg','.bmp','png'))]\n",
    "    frames.sort()\n",
    "    print(len(frames))\n",
    "    for i in range(25,100,1):\n",
    "        sample = torch.FloatTensor(2, N_FRAME-1, 128*160)\n",
    "        model,  dictionary, Drr, Dtheta = loadModel(ckpt_file)\n",
    "        print(i)\n",
    "        for ii in range(i, FRA+i): #for INCR WNDW range(25,FRA+i)\n",
    "            imgname = os.path.join(rootDir,folder,frames[ii])\n",
    "            img = Image.open(imgname)\n",
    "            img1 = process_im(np.array(img))/255.\n",
    "\n",
    "            imgname = os.path.join(rootDir,folder,frames[ii+1])\n",
    "            img = Image.open(imgname)\n",
    "            img2 = process_im(np.array(img))/255.\n",
    "\n",
    "            u, v,_ = pyflow.coarse2fine_flow( img2, img1, alpha, ratio, minWidth,\n",
    "                    nOuterFPIterations, nInnerFPIterations, nSORIterations, colType)\n",
    "            \n",
    "            flow = np.concatenate((u[..., None], v[..., None]), axis=2)\n",
    "            flow = np.transpose(flow,(2,0,1))\n",
    "            \n",
    "            sample[:,ii-i,:] = torch.from_numpy(flow.reshape(2,128*160)).type(torch.FloatTensor) #for INCR WNDW sample[:,ii-25,:]\n",
    "        \n",
    "        #sample[0,0,10290] = 2\n",
    "        alSample = alignOFtest(sample.view(2,9,128,160).unsqueeze(0),9)\n",
    "        showOFs(alSample, sample.view(2,9,128,160).unsqueeze(0), 9)\n",
    "        #alSample = sample\n",
    "        imgname = os.path.join(rootDir,folder,frames[ii+2])\n",
    "        img = Image.open(imgname)\n",
    "        original = process_im(np.array(img))/255.\n",
    "\n",
    "        imgname = os.path.join(rootDir,folder,frames[ii+1])\n",
    "        img = Image.open(imgname)\n",
    "        tenth = process_im(np.array(img))/255.\n",
    "\n",
    "        inputData = alSample.cuda()\n",
    "        #start = current_milli_time()\n",
    "        with torch.no_grad():\n",
    "            sparse = model.forward(Variable(inputData.view((2, 9, 128*160)).type(torch.FloatTensor).cuda(gpu_id)))\n",
    "            c = sparse.cpu().numpy()\n",
    "            c_list.append(c)\n",
    "            \n",
    "        ## INCREASING WINDOW  \n",
    "        #N_FRAME += 1\n",
    "        #T += 1\n",
    "        \n",
    "        prediction = torch.matmul(torch.t(dictionary),sparse)[:,FRA,:].data.permute(1,0).resize(128,160,2)\n",
    "        \n",
    "        tmp1 = torch.zeros((128,160, 3))\n",
    "        tmp2 = torch.zeros((128,160, 3)) \n",
    "        tmp3 = torch.zeros((128,160, 3)) \n",
    "        tmp4 = torch.zeros((128,160, 3)) \n",
    "        tmp5 = torch.zeros((128,160, 3)) \n",
    "        \n",
    "        tmp1[:,:,0:2] = prediction\n",
    "        tmp2[:,:,0:2] = sample[:,FRA-2,:].view((2,128,160)).permute(1,2,0)\n",
    "        tmp3[:,:,0:2] = sample[:,FRA-1,:].view((2,128,160)).permute(1,2,0)\n",
    "        tmp4[:,:,0:2] = alSample[0,:,FRA-2,:,:].permute(1,2,0)\n",
    "        tmp5[:,:,0:2] = alSample[0,:,FRA-1,:,:].permute(1,2,0)\n",
    "        \n",
    "        tmpt = torch.cat((tmp1, tmp2, tmp3, tmp4, tmp5), 0)\n",
    "        scipy.misc.imsave('Pred.png', tmpt.detach().cpu().numpy())\n",
    "        \n",
    "        img_back = scipwarp(tenth,prediction[:,:,0],prediction[:,:,1])\n",
    "        img_back = np.clip(img_back, 0, 1.)\n",
    "        \n",
    "        plt.imshow(original, cmap='gray')\n",
    "        plt.show()\n",
    "        plt.imshow(img_back, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        meanserror = np.mean( (img_back - original) ** 2 )\n",
    "        mse.append(meanserror)\n",
    "        peaksnr = 10*math.log10(1./meanserror)\n",
    "        psnr.append(peaksnr)\n",
    "        ssim.append(SSIM(original, img_back))\n",
    "        \n",
    "    print (np.mean(ssim), np.mean(psnr), np.mean(mse))\n",
    "        \n",
    "    print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
